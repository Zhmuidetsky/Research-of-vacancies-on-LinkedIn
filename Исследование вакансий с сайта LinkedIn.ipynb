{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4afc8590",
   "metadata": {},
   "source": [
    "# **Проект исследования вакансий Junior аналитиков с сайта LinkedIn**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57777595",
   "metadata": {},
   "source": [
    "## **Цель исследования**\n",
    "\n",
    "Визуализировать информацию о рынке вакансий для аналитиков в Европе, в разрезе:\n",
    "- по стране и по типу занятости\n",
    "- общее количество вакансий\n",
    "- нанимающих компаний с указанием количества вакансий,\n",
    "- ТОП 10 сфер деятельности компаний, которые нанимают аналитиков\n",
    "- размер компаний и количество вакансий\n",
    "- требуемые хард скилы\n",
    "- Дополнительно (необязательно) - зависимость количества кандидатов на вакансию от даты публикации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee1f99",
   "metadata": {},
   "source": [
    "### **Описание  данных:**\n",
    "\n",
    "Предоставлен датасет с сырыми данными после парсинга сайта LinkedIn, который необходимо обработать и создать датасет, содержащий:\n",
    "- наименование вакансии\n",
    "- город\n",
    "- страна\n",
    "- тип занятости (online, hybride, on-site)\n",
    "- компания\n",
    "- размер компании (количество работников)\n",
    "- сфера деятельности компании\n",
    "- требуемые хард скилы\n",
    "- дата публикации вакансии\n",
    "- количество кандидатов на вакансию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07697a4",
   "metadata": {},
   "source": [
    "### **План исследования**\n",
    "\n",
    "Работать будем в следующем порядке:\n",
    "- обработка исходного файла и выделение в нем требуемых признаков\n",
    "- проверка наличия дубликатов\n",
    "- проверка наличия нерелевантных вакансий\n",
    "- удаление ненужных атрибутов\n",
    "- создание дашборда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ef9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# перед началом работы импортируем библиотеки, которые могут понадобиться в работе над проектом\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from urllib.parse import urlencode \n",
    "import re\n",
    "import requests\n",
    "from calendar import day_name\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb8c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4390173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# установим неограниченную ширину колонок датафреймов\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcbd92d",
   "metadata": {},
   "source": [
    "## **Импорт данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# используя конструкцию try-ecxept для возможности открыть локально и с внешнего источника\n",
    "try:\n",
    "    with open(r'C:\\Users\\ezhmui04\\Documents\\Поиск работы\\Тестовые задания\\masterskaya_parsing_LinkedIn_2023_05_23.csv', mode='r', encoding='utf-8',\n",
    "              errors=None, newline=None, closefd=True, opener=None) as fp:\n",
    "        raw_data = fp.read()\n",
    "\n",
    "except:\n",
    "\n",
    "    base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "    public_key = 'https://disk.yandex.ru/d/gsL7aCpUvlysoQ'  # Сюда вписываете вашу ссылку\n",
    "\n",
    "    # Получаем загрузочную ссылку\n",
    "    final_url = base_url + urlencode(dict(public_key=public_key))\n",
    "    response = requests.get(final_url)\n",
    "    download_url = response.json()['href']\n",
    "\n",
    "    # Загружаем файл и сохраняем его в текущем директории\n",
    "    download_response = requests.get(download_url)\n",
    "    with open('masterskaya_parsing_LinkedIn_2023_05_23.csv', 'wb') as fp:\n",
    "        fp.write(download_response.content)\n",
    "        \n",
    "    # и записываем из него данные в переменную сырых данных\n",
    "    with open(r'masterskaya_parsing_LinkedIn_2023_05_23.csv', mode='r', encoding='utf-8',\n",
    "        errors=None, newline=None, closefd=True, opener=None) as fp:\n",
    "        raw_data = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd27a16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# используя конструкцию try-ecxept для возможности открыть локально и с внешнего источника\n",
    "# для загрузки сразу в датафрейм\n",
    "try:\n",
    "    raw_df = pd.read_csv(r'C:\\Users\\ezhmui04\\Documents\\Поиск работы\\Тестовые задания\\masterskaya_parsing_LinkedIn_2023_05_23.csv')\n",
    "    \n",
    "except:\n",
    "\n",
    "    # используем api\n",
    "    base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "    public_key = 'https://disk.yandex.ru/d/gsL7aCpUvlysoQ'\n",
    "    # получаем url\n",
    "    final_url = base_url + urlencode(dict(public_key=public_key))\n",
    "    response = requests.get(final_url)\n",
    "    download_url = response.json()['href']\n",
    "    # загружаем файл в df\n",
    "    download_response = requests.get(download_url)\n",
    "    raw_df = pd.read_csv(download_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5194f8",
   "metadata": {},
   "source": [
    "## **Применение \"супа\" разными парсерами**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробуем распарсить данные разными парсерами\n",
    "soup = BeautifulSoup(raw_data, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in soup.find_all('h2'):\n",
    "    print(job.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4404291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробуем распарсить данные разными парсерами\n",
    "soup_html = BeautifulSoup(raw_data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b465409",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in soup_html.find_all('h2'):\n",
    "    print(job.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e2152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# пробуем распарсить данные разными парсерами\n",
    "soup_html5 = BeautifulSoup(raw_data, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471751ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for job in soup_html5.find_all('h2'):\n",
    "    print(job.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae02cab",
   "metadata": {},
   "source": [
    "## **Страницы в виде датафрейма**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd837d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7878d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8c030a",
   "metadata": {},
   "source": [
    "У нас сформировался датафрейм из двух колонок, в первой идет порядковый номер, во второй - содержимое одной страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91138b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем в переменную значение одной страницы, что бы полее подробно его изучить\n",
    "soup_test = BeautifulSoup(raw_df.iloc[0]['html'], 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1df79",
   "metadata": {},
   "source": [
    "## **Рассмотрение одного блока с вакансией на странице**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc721b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# и посмотрим на него в понятном виде\n",
    "print(soup_test.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6946488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job = soup_test.find_all('h2', class_ = 't-24 t-bold jobs-unified-top-card__job-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a2e880",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = soup_test.find('h2', class_ = 't-24 t-bold jobs-unified-top-card__job-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4bb39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16650937",
   "metadata": {},
   "source": [
    "# **Общий вывод исследования**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "439px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
